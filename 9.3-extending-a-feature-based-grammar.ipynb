{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 扩展基于特征的文法\n",
    "\n",
    "## 子类别\n",
    "\n",
    "第 8 章中我们增强了类别标签来表示不同类别的动词，分别用标签 IV 和 TV 表示不及物动词和及物动词，编写的产生式为：\n",
    "\n",
    "    VP -> IV\n",
    "    VP -> TV NP\n",
    "    \n",
    "虽然 IV 和 TV 是两种不同类型的 V，但它们都只是 CFG 中的原子非终结符，并不能告诉我们有关 V 的一般信息，例如：我们不能说 V 类的所有词汇都可以标记时态，这是因为像 walk，see 这样的动词都属于 IV 或 TV，而不属于 V。我们期望用类别的属性来替代这两个类别标签。\n",
    "\n",
    "广义短语结构文法（Generalized Phrase Structure Grammar，GPSG）通过允许词汇类别支持子类别特征来解决这个问题，我们用 SUBCAT 来代表词汇类别的子类特征，对于 V，其可选的值有 intrans、trans 和 clause：\n",
    "\n",
    "    VP[TENSE=?t, NUM=?n] -> V[SUBCAT=intrans, TENSE=?t, NUM=?n]\n",
    "    VP[TENSE=?t, NUM=?n] -> V[SUBCAT=trans, TENSE=?t, NUM=?n] NP\n",
    "    VP[TENSE=?t, NUM=?n] -> V[SUBCAT=clause, TENSE=?t, NUM=?n] SBar\n",
    "\n",
    "    V[SUBCAT=intrans, TENSE=pres, NUM=sg] -> 'disappears' | 'walks'\n",
    "    V[SUBCAT=trans, TENSE=pres, NUM=sg] -> 'sees' | 'likes'\n",
    "    V[SUBCAT=clause, TENSE=pres, NUM=sg] -> 'says' | 'claims'\n",
    "\n",
    "    V[SUBCAT=intrans, TENSE=pres, NUM=pl] -> 'disappear' | 'walk'\n",
    "    V[SUBCAT=trans, TENSE=pres, NUM=pl] -> 'see' | 'like'\n",
    "    V[SUBCAT=clause, TENSE=pres, NUM=pl] -> 'say' | 'claim'\n",
    "\n",
    "    V[SUBCAT=intrans, TENSE=past, NUM=?n] -> 'disappeared' | 'walked'\n",
    "    V[SUBCAT=trans, TENSE=past, NUM=?n] -> 'saw' | 'liked'\n",
    "    V[SUBCAT=clause, TENSE=past, NUM=?n] -> 'said' | 'claimed'\n",
    "    \n",
    "在动词的第三个类别中，我们指定了一个类别 SBar，这是一个从句标签，我们需要两个进一步的产生式来分析这样的句子（Comp 为补语）：\n",
    "\n",
    "    SBar -> Comp S\n",
    "    Comp -> 'that'\n",
    "    \n",
    "产生的结构如下：\n",
    "    \n",
    "![ch09-tree-10.png](resources/ch09-tree-10.png)\n",
    "\n",
    "在核心驱动短语结构文法（Head-driven Phrase Structure Grammar，HPSG）中也有关于子类别的概念，不同于 GPSG 中用 SUBCAT 值作为产生式的索引，HPSG 中的 SUBCAT 值直接编码中心词的配价（即该中心词能结合的参数列表）。例如，动词 put 带 NP 和 PP 补语（put the book on the table）可以表示为：\n",
    "\n",
    "    V[SUBCAT=<NP, NP, PP>]\n",
    "    \n",
    "这是说动词可以结合三个参数，最左边的是主语 NP，后面的 NP 和 PP 则构成补语。当 put 与适当的补语结合后，SUBCAT 中已满足的参数就可以去掉，只留下一个主语 NP，也就是传统意义上的 VP 形式：\n",
    "\n",
    "    V[SUBCAT=<NP>]\n",
    "    \n",
    "最终，整个句子可以被看做不需要更多参数的动词类别，因此其 SUBCAT 值为空列表:\n",
    "\n",
    "    V[SUBCAT=<>]\n",
    "\n",
    "组合过程的树状结构如下图所示：\n",
    "\n",
    "![ch09-tree-11.png](resources/ch09-tree-11.png)\n",
    "\n",
    "## 核心词回顾\n",
    "\n",
    "前面我们说过，V 类别的表达式是 VP 类别短语的核心。同样，N 是 NP 的核心词，A（形容词）是 AP 的核心词，P（介词）是 PP 的核心词。并非所有的短语都有核心词，例如：一般认为连词短语（the book and the bell）缺乏核心词。我们希望我们的文法形式能表达它所持有的父节点/核心子节点之间的关系，也就是将 V 和 VP 这样的类别标签通过某些特征关联起来。\n",
    "\n",
    "X-bar 句法（X 可以是 N、V、A 和 P）通过抽象出**短语级别**的概念来解决这个问题，它通常认为有三个这样的短语级别。例如：如果 N 表示词汇的级别，那么 N' 代表更高一层级别，对应传统的 Nom，N'' 表示短语这一级别，类似于 NP。下图中的 a 演示了这种表示结构，而 b 则对应传统的结构：\n",
    "\n",
    "a. ![ch09-tree-12.png](resources/ch09-tree-12.png)\n",
    "\n",
    "b. ![ch09-tree-13.png](resources/ch09-tree-13.png)\n",
    "\n",
    "结构 a 中的核心词是 N，而 N' 和 N'' 则被称为 N 的**（短语）投影**，其中 N'' 是**最大投影**，有时候 N 也可以被称为**零投影**。X-bar 文法的一个中心思想就是所有成分都有类似的结构，核心词汇 X 的直接补语总是位于核心词的兄弟位置，而修饰成分则位于中间类别 X' 的兄弟位置，如下图所示：\n",
    "\n",
    "![ch09-tree-14.png](resources/ch09-tree-14.png)\n",
    "\n",
    "可以用下面的产生式来描述上述结构：\n",
    "\n",
    "    S -> N[BAR=2] V[BAR=2]\n",
    "    N[BAR=2] -> Det N[BAR=1]\n",
    "    N[BAR=1] -> N[BAR=1] P[BAR=2]\n",
    "    N[BAR=1] -> N[BAR=0] P[BAR=2]\n",
    "    N[BAR=1] -> N[BAR=0]XS\n",
    "    \n",
    "## 助动词和倒装\n",
    "\n",
    "倒装从句是指主语和动词互换位置的从句，常出现在疑问句中和表示否定意义的副词之后：\n",
    "\n",
    "    a. Do you like children?\n",
    "    b. Can Jody walk?\n",
    "    a. Rarely do you see Kim.\n",
    "    b. Never have I seen this dog.\n",
    "\n",
    "可以放置在倒装从句开头的动词叫做**助动词**，包括 do、can、have、be、will、shall 等，通常用以下产生式来捕捉这种结构：\n",
    "\n",
    "    S[+INV] -> V[+AUX] NP VP\n",
    "    \n",
    "S[+INV] 表示倒装从句，它包含一个助动词，后面跟着一个 NP 和 VP：\n",
    "\n",
    "![ch09-tree-15.png](resources/ch09-tree-15.png)\n",
    "\n",
    "## 无限制依赖成分\n",
    "\n",
    "考虑下面两组对比（带 * 号的为不合法语句）：\n",
    "\n",
    "    a. You like Jody.\n",
    "    b. *You like.\n",
    "\n",
    "    a. You put the card into the slot.\n",
    "    b. *You put into the slot.\n",
    "    c. *You put the card.\n",
    "    d. *You put.\n",
    "\n",
    "动词 like 需要一个 NP 补语，而 put 需要一个跟随其后的 NP 和 PP，这些补语是必须的，省略它们会导致不符合语法。然而，有些时候上下文中强制性的补语却可以省略：\n",
    "\n",
    "    a. Kim knows who you like.\n",
    "    b. This music, you really like.\n",
    "    c. Which card do you put into the slot?\n",
    "    d. Which slot do you put the card into?\n",
    "\n",
    "也就是说，一个强制性补语可以被省略，如果句子有适当的**填充**，例如 a 中的疑问词 who，b 中的前置主题 this music，c 和 d 中的 wh 短语 which card/slot。通常说这样的句子包含一个**缺口**，在那里强制性补语被省略了，我们可以用下划线标出缺口的位置：\n",
    "\n",
    "    a. Which card do you put __ into the slot?\n",
    "    b. Which slot do you put the card into __?\n",
    "\n",
    "所以，如果填充词允许，缺口就能出现。相反，填充词只会出现在句子希望有缺口的地方，下面的例子就是填充此出现在了没有缺口的句子中，因此是不符合文法的：\n",
    "\n",
    "    a. *Kim knows who you like Jody.\n",
    "    b. *This music, you really like hip-hop.\t\n",
    "    c. *Which card do you put this into the slot?\n",
    "    d. *Which slot do you put the card into this one?\n",
    "\n",
    "填充词和缺口之间的同时出现有时候被称为**依赖**，一个填充词和它许可的缺口之间相互作用的原因有很多种，因此我们很难列举出所有可能的情况，填充词和缺口之间的距离没有上界，这一事实可以很容易地使用包含句子补语的结构来说明：\n",
    "\n",
    "    a. Who do you like __?\n",
    "    b. Who do you claim that you like __?\n",
    "    c. Who do you claim that Jody says that you like __?\n",
    "\n",
    "因为我们可以无限加深句子补语的递归，在整个句子中缺口可以无限远的被填充。已经有多种机制可以处理形式化文法中的无限依赖，这里我们说明广义短语结构文法 GPSG 中使用的方法：使用**斜线类别 Y/XP**，表示类别 Y 的短语缺少一个类别 XP 的子成分。例如：S/NP 是缺少一个 NP 的 S。更具体的例子如下：\n",
    "\n",
    "![ch09-tree-16.png](resources/ch09-tree-16.png)\n",
    "\n",
    "树的顶端部分引入了填充词 who（作为 NP[+wh] 类表达式对待）和相应的包含缺口的成分 S/NP。缺口信息沿着树经过 VP/NP 类别，最终到达 NP/NP 类别，由于 NP/NP 可以接受空字符串，因此文法解析完成。\n",
    "\n",
    "我们可以很轻易地将斜线类别纳入到现有的基于特征的框架，也就是将 S/NP 变为 S[SLASH=NP]。下面的例子给出了使用斜线类别的具有倒装从句和长距离依赖产生式的文法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% start S\n",
      "# ###################\n",
      "# Grammar Productions\n",
      "# ###################\n",
      "S[-INV] -> NP VP\n",
      "S[-INV]/?x -> NP VP/?x\n",
      "S[-INV] -> NP S/NP\n",
      "S[-INV] -> Adv[+NEG] S[+INV]\n",
      "S[+INV] -> V[+AUX] NP VP\n",
      "S[+INV]/?x -> V[+AUX] NP VP/?x\n",
      "SBar -> Comp S[-INV]\n",
      "SBar/?x -> Comp S[-INV]/?x\n",
      "VP -> V[SUBCAT=intrans, -AUX]\n",
      "VP -> V[SUBCAT=trans, -AUX] NP\n",
      "VP/?x -> V[SUBCAT=trans, -AUX] NP/?x\n",
      "VP -> V[SUBCAT=clause, -AUX] SBar\n",
      "VP/?x -> V[SUBCAT=clause, -AUX] SBar/?x\n",
      "VP -> V[+AUX] VP\n",
      "VP/?x -> V[+AUX] VP/?x\n",
      "# ###################\n",
      "# Lexical Productions\n",
      "# ###################\n",
      "V[SUBCAT=intrans, -AUX] -> 'walk' | 'sing'\n",
      "V[SUBCAT=trans, -AUX] -> 'see' | 'like'\n",
      "V[SUBCAT=clause, -AUX] -> 'say' | 'claim'\n",
      "V[+AUX] -> 'do' | 'can'\n",
      "NP[-WH] -> 'you' | 'cats'\n",
      "NP[+WH] -> 'who'\n",
      "Adv[+NEG] -> 'rarely' | 'never'\n",
      "NP/NP ->\n",
      "Comp -> 'that'\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.data.show_cfg('grammars/book_grammars/feat1.fcfg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该文法中包含了一个“缺口引进”产生式，即 S[-INV] -> NP S/NP。为了正确地预填充斜线特征，我们需要为扩展 S、VP 和 NP 的产生式中箭头两侧的斜线添加变量值，例如：VP/?x -> V SBar/?x 是 VP -> V SBar 的斜线版本，也就是说，可以为一个结构的父节点 VP 指定斜线值，只要为其子节点 SBar 也指定同样的值。最后，NP/NP -> 允许 NP 上的斜线信息为空字符串。\n",
    "\n",
    "利用该文法，我们可以分析序列 who do you claim that you like："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[-INV]\n",
      "  (NP[+WH] who)\n",
      "  (S[+INV]/NP[]\n",
      "    (V[+AUX] do)\n",
      "    (NP[-WH] you)\n",
      "    (VP[]/NP[]\n",
      "      (V[-AUX, SUBCAT='clause'] claim)\n",
      "      (SBar[]/NP[]\n",
      "        (Comp[] that)\n",
      "        (S[-INV]/NP[]\n",
      "          (NP[-WH] you)\n",
      "          (VP[]/NP[] (V[-AUX, SUBCAT='trans'] like) (NP[]/NP[] )))))))\n"
     ]
    }
   ],
   "source": [
    "tokens = 'who do you claim that you like'.split()\n",
    "cp = nltk.load_parser('grammars/book_grammars/feat1.fcfg')\n",
    "for tree in cp.parse(tokens):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图形化的表示为：\n",
    "\n",
    "![ch09-tree-17.png](resources/ch09-tree-17.png)\n",
    "\n",
    "该文法也可以分析没有缺口的句子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[-INV]\n",
      "  (NP[-WH] you)\n",
      "  (VP[]\n",
      "    (V[-AUX, SUBCAT='clause'] claim)\n",
      "    (SBar[]\n",
      "      (Comp[] that)\n",
      "      (S[-INV]\n",
      "        (NP[-WH] you)\n",
      "        (VP[] (V[-AUX, SUBCAT='trans'] like) (NP[-WH] cats))))))\n"
     ]
    }
   ],
   "source": [
    "tokens = 'you claim that you like cats'.split()\n",
    "for tree in cp.parse(tokens):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此外，它还允许没有 wh 结构的倒装句："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[-INV]\n",
      "  (Adv[+NEG] rarely)\n",
      "  (S[+INV]\n",
      "    (V[+AUX] do)\n",
      "    (NP[-WH] you)\n",
      "    (VP[] (V[-AUX, SUBCAT='intrans'] sing))))\n"
     ]
    }
   ],
   "source": [
    "tokens = 'rarely do you sing'.split()\n",
    "for tree in cp.parse(tokens):\n",
    "    print(tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

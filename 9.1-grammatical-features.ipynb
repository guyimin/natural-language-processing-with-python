{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文法特征\n",
    "\n",
    "第 6 章中我们通过检测文本的特征建立分类器，那些特征可能非常简单，如提取一个单词的最后一个字母等。本章中，我们将探讨特征在建立基于规则的文法中的作用。与第 6 章中自动提取的特征不同，这里我们手动声明词和短语的特征："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "kim = {'CAT': 'NP', 'ORTH': 'Kim', 'REF': 'k'}\n",
    "chase = {'CAT': 'V', 'ORTH': 'chased', 'REL': 'chase'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "字典对象 kim 和 chase 存储了两组特征值，CAT 代表文法类别，ORTH 代表单词的拼写，还有一些其它面向语义的特征：kim 的 REF 意在给出 kim 的指示物，chase 的 REL 则给出 chase 表示的关系。这样的特征和特征值对被称为**特征结构**。\n",
    "\n",
    "特征结构包含了各种有关文法实体的信息，我们可以进一步增加属性。例如：对于 chase， 主语扮演施事（agent）角色，而宾语扮演受事（patient）角色。我们添加这些信息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chase['AGT'] = 'sbj'\n",
    "chase['PAT'] = 'obj'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们来处理句子 Kim chased Lee，我们要“绑定”动词的施事角色给主语，受事角色给宾语，可以通过链接 NP 的 REF 特征来达到这一目的（这里假设了动词左侧和右侧的 NP 分别是主语和宾语）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORTH  => chased\n",
      "REL   => chase\n",
      "AGT   => k\n",
      "PAT   => l\n"
     ]
    }
   ],
   "source": [
    "sent = 'Kim chased Lee'\n",
    "tokens = sent.split()\n",
    "lee = {'CAT': 'NP', 'ORTH': 'Lee', 'REF': 'l'}\n",
    "\n",
    "def lex2fs(word):\n",
    "    for fs in [kim, lee, chase]:\n",
    "        if fs['ORTH'] == word:\n",
    "            return fs\n",
    "        \n",
    "subj, verb, obj = lex2fs(tokens[0]), lex2fs(tokens[1]), lex2fs(tokens[2])\n",
    "verb['AGT'] = subj['REF']\n",
    "verb['PAT'] = obj['REF']\n",
    "for k in ['ORTH', 'REL', 'AGT', 'PAT']:\n",
    "    print('%-5s => %s' % (k, verb[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样的方法可以适用不同的动词，例如 surprise，不同之处在于这种情况下，主语将扮演来源（source，SRC）角色，宾语将扮演体验者（experiencer，EXP）角色："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise = {'CAT': 'V', 'ORTH': 'surprised', 'REL': 'surprise',\n",
    "            'SRC': 'sbj', 'EXP': 'obj'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征结构是非常强大的，接下来我们将分析如何将上下文无关文法扩展到合适的特征结构。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 句法协议\n",
    "\n",
    "在英语中，名词通常被标记为单数或附属，例如 this dog 和 these dogs 是符合语法的，而 these dog 和 this dogs 则不是，也就是说名词短语中使用的指示词和名词搭配是由限制的。动词的现在时态也有类似的变化，例如 the dog runs 和 the dogs run。这种同时的变化被称为**协议（agreement）**，下表展示了英语中规则动词的协议规范：\n",
    "\n",
    "|          | 单数           | 复数     |\n",
    "|----------|----------------|----------|\n",
    "| 第一人称 | I run          | we run   |\n",
    "| 第二人称 | you run        | you run  |\n",
    "| 第三人称 | he/she/it runs | they run |\n",
    "\n",
    "让我们看看当我们在一个上下文无关文法中编码这些协议约束会发生什么。我们从一个简单的 CFG 开始：\n",
    "\n",
    "    S   ->   NP VP\n",
    "    NP  ->   Det N\n",
    "    VP  ->   V\n",
    "\n",
    "    Det  ->  'this'\n",
    "    N    ->  'dog'\n",
    "    V    ->  'runs'\n",
    "    \n",
    "该文法可以产生句子 this dog runs，然而我们真正想要做的是也能产生 these dogs run，同时阻止不必要的序列如 this dogs run 和 these dog runs：\n",
    "\n",
    "    S -> NP_SG VP_SG\n",
    "    S -> NP_PL VP_PL\n",
    "    NP_SG -> Det_SG N_SG\n",
    "    NP_PL -> Det_PL N_PL\n",
    "    VP_SG -> V_SG\n",
    "    VP_PL -> V_PL\n",
    "\n",
    "    Det_SG -> 'this'\n",
    "    Det_PL -> 'these'\n",
    "    N_SG -> 'dog'\n",
    "    N_PL -> 'dogs'\n",
    "    V_SG -> 'runs'\n",
    "    V_PL -> 'run'\n",
    "    \n",
    "在扩展 S 的地方，我们现在有两个产生式，一个覆盖单数主语 NP 和 VP，另一个覆盖复数主语 NP 和 VP，原始文法的所有产生式都有两个与之对应。在小规模文法中这不是什么问题，但是在更大的涵盖了一定量英语成分的文法中，产生式的数量会成爆炸式地增长。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用属性和约束\n",
    "\n",
    "非正式的语言类别都具有属性，例如：名词具有复数的属性，我们可以用如下符号来表示，它的意思是类别 N 有一个**（文法）特征**叫做 NUM（数字 number 的简写），此特征的值是 pl（复数 plural 的简写）：\n",
    "\n",
    "    N[NUM=pl]\n",
    "    \n",
    "我们可以添加类似的注解给其他类别：\n",
    "\n",
    "    Det[NUM=sg] -> 'this'\n",
    "    Det[NUM=pl] -> 'these'\n",
    "\n",
    "    N[NUM=sg] -> 'dog'\n",
    "    N[NUM=pl] -> 'dogs'\n",
    "    V[NUM=sg] -> 'runs'\n",
    "    V[NUM=pl] -> 'run'\n",
    "    \n",
    "当我们在产生式中允许使用特征值变量时，事情变得有趣了起来：\n",
    "\n",
    "    S -> NP[NUM=?n] VP[NUM=?n]\n",
    "    NP[NUM=?n] -> Det[NUM=?n] N[NUM=?n]\n",
    "    VP[NUM=?n] -> V[NUM=?n]\n",
    "    \n",
    "这里我们使用 ?n 来作为 NUM 值得变量，它可以在给定的产生式中被实例化为 sg 或 pl。值得注意的是，在一个产生式中所有的 ?n 需要取同样的值，也就是在 S -> NP VP 中，不管 NP 为特征 NUM 取什么值，VP 必须取同样的值。\n",
    "\n",
    "我们用树的形式来思考这些特征限制是如何工作的。首先词汇产生式承认下面深度为 1 的树：\n",
    "\n",
    "![ch09-tree-1.png](resources/ch09-tree-1.png)\n",
    "\n",
    "接下来通过 NP -> Det N 来产生深度为 2 的树，可以看出后两种情况是不允许的，用顶端节点值为 FAIL 来表示，这是由于它们字数的根节点 NUM 值不同。\n",
    "\n",
    "![ch09-tree-2.png](resources/ch09-tree-2.png)\n",
    "\n",
    "再结合扩展 S 的产生式，可以得到 these dogs run 的解析树：\n",
    "\n",
    "![ch09-tree-3.png](resources/ch09-tree-3.png)\n",
    "\n",
    "在上面的例子中限定词 Det 有 this 和 these 两种形式，然而英语中的其他限定词对与它们结合的名词数量并不挑剔：\n",
    "\n",
    "    Det[NUM=sg] -> 'the' | 'some' | 'any'\n",
    "    Det[NUM=pl] -> 'the' | 'some' | 'any'\n",
    "    \n",
    "一个更优雅的写法是保留 NUM 的值为未指定，让它匹配与它结合的任何名词的数量：\n",
    "\n",
    "    Det[NUM=?n] -> 'the' | 'some' | 'any'\n",
    "    \n",
    "事实上我们可以更简单些，在这样的产生式中不给 NUM 任何指定：\n",
    "    \n",
    "    Det -> 'the' | 'some' | 'any'\n",
    "    \n",
    "下面是一个较为完整的基于特征的文法的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% start S\n",
      "# ###################\n",
      "# Grammar Productions\n",
      "# ###################\n",
      "# S expansion productions\n",
      "S -> NP[NUM=?n] VP[NUM=?n]\n",
      "# NP expansion productions\n",
      "NP[NUM=?n] -> N[NUM=?n] \n",
      "NP[NUM=?n] -> PropN[NUM=?n] \n",
      "NP[NUM=?n] -> Det[NUM=?n] N[NUM=?n]\n",
      "NP[NUM=pl] -> N[NUM=pl] \n",
      "# VP expansion productions\n",
      "VP[TENSE=?t, NUM=?n] -> IV[TENSE=?t, NUM=?n]\n",
      "VP[TENSE=?t, NUM=?n] -> TV[TENSE=?t, NUM=?n] NP\n",
      "# ###################\n",
      "# Lexical Productions\n",
      "# ###################\n",
      "Det[NUM=sg] -> 'this' | 'every'\n",
      "Det[NUM=pl] -> 'these' | 'all'\n",
      "Det -> 'the' | 'some' | 'several'\n",
      "PropN[NUM=sg]-> 'Kim' | 'Jody'\n",
      "N[NUM=sg] -> 'dog' | 'girl' | 'car' | 'child'\n",
      "N[NUM=pl] -> 'dogs' | 'girls' | 'cars' | 'children' \n",
      "IV[TENSE=pres,  NUM=sg] -> 'disappears' | 'walks'\n",
      "TV[TENSE=pres, NUM=sg] -> 'sees' | 'likes'\n",
      "IV[TENSE=pres,  NUM=pl] -> 'disappear' | 'walk'\n",
      "TV[TENSE=pres, NUM=pl] -> 'see' | 'like'\n",
      "IV[TENSE=past] -> 'disappeared' | 'walked'\n",
      "TV[TENSE=past] -> 'saw' | 'liked'\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.data.show_cfg('grammars/book_grammars/feat0.fcfg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文法开头的 % start S 告诉分析器以 S 作为文法的开始符号，同时一个句法类别可以有多个特征，如 IV[TENSE=pres,  NUM=pl]，可以添加任意数量的特征。\n",
    "\n",
    "我们可以使用 [nltk.load_parse](http://www.nltk.org/_modules/nltk/parse/util.html#load_parser) 函数来加载基于特征的文法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|.Kim .like.chil.|\n",
      "Leaf Init Rule:\n",
      "|[----]    .    .| [0:1] 'Kim'\n",
      "|.    [----]    .| [1:2] 'likes'\n",
      "|.    .    [----]| [2:3] 'children'\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[----]    .    .| [0:1] PropN[NUM='sg'] -> 'Kim' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[----]    .    .| [0:1] NP[NUM='sg'] -> PropN[NUM='sg'] *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[---->    .    .| [0:1] S[] -> NP[NUM=?n] * VP[NUM=?n] {?n: 'sg'}\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    [----]    .| [1:2] TV[NUM='sg', TENSE='pres'] -> 'likes' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    [---->    .| [1:2] VP[NUM=?n, TENSE=?t] -> TV[NUM=?n, TENSE=?t] * NP[] {?n: 'sg', ?t: 'pres'}\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    .    [----]| [2:3] N[NUM='pl'] -> 'children' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    .    [----]| [2:3] NP[NUM='pl'] -> N[NUM='pl'] *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    .    [---->| [2:3] S[] -> NP[NUM=?n] * VP[NUM=?n] {?n: 'pl'}\n",
      "Feature Single Edge Fundamental Rule:\n",
      "|.    [---------]| [1:3] VP[NUM='sg', TENSE='pres'] -> TV[NUM='sg', TENSE='pres'] NP[] *\n",
      "Feature Single Edge Fundamental Rule:\n",
      "|[==============]| [0:3] S[] -> NP[NUM='sg'] VP[NUM='sg'] *\n",
      "(S[]\n",
      "  (NP[NUM='sg'] (PropN[NUM='sg'] Kim))\n",
      "  (VP[NUM='sg', TENSE='pres']\n",
      "    (TV[NUM='sg', TENSE='pres'] likes)\n",
      "    (NP[NUM='pl'] (N[NUM='pl'] children))))\n"
     ]
    }
   ],
   "source": [
    "tokens = 'Kim likes children'.split()\n",
    "cp = nltk.load_parser('grammars/book_grammars/feat0.fcfg', trace=2)\n",
    "for tree in cp.parse(tokens):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 术语\n",
    "\n",
    "前面我们看到了像 sg 和 pl 这样的特征值，这些简单的值通常被称为**原子**，也就是说它们不能被分解成更小的部分。原子值得一种特殊情况时**布尔值**，也就是说值仅仅指定一个属性是真还是假。例如：我们用布尔特征 AUX 区分**助动词**，如 can、may、will 和 do，就可以写成 AUX=+ 或 AUX=-，有一个广泛采用的缩写约定为 +AUX 和 -AUX。\n",
    "\n",
    "    V[TENSE=pres, +AUX] -> 'can'\n",
    "    V[TENSE=pres, +AUX] -> 'may'\n",
    "    V[TENSE=pres, -AUX] -> 'walks'\n",
    "    V[TENSE=pres, -AUX] -> 'likes'\n",
    "    \n",
    "除了原子值特征以外，特征可能本省就是特征结构的值。例如：我们可以将协议特征组合在一起（如：人称、数量和性别）作为一个类别的不同部分，表示为 AGR，这种情况下，AGR 就是一个**复杂值**，在格式上称为**属性值矩阵**（attribute value matrix，AVM）。\n",
    "\n",
    "    [POS = N           ]\n",
    "    [                  ]\n",
    "    [AGR = [PER = 3   ]]\n",
    "    [      [NUM = pl  ]]\n",
    "    [      [GND = fem ]]\n",
    "\n",
    "当我们有可能使用像 AGR 这样的特征时，我们可以重构前面的文法，使协议特征捆绑在一起：\n",
    "\n",
    "    S                    -> NP[AGR=?n] VP[AGR=?n]\n",
    "    NP[AGR=?n]           -> PropN[AGR=?n]\n",
    "    VP[TENSE=?t, AGR=?n] -> Cop[TENSE=?t, AGR=?n] Adj\n",
    "\n",
    "    Cop[TENSE=pres,  AGR=[NUM=sg, PER=3]] -> 'is'\n",
    "    PropN[AGR=[NUM=sg, PER=3]]            -> 'Kim'\n",
    "    Adj                                   -> 'happy'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

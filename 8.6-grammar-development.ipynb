{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文法开发\n",
    "\n",
    "我们尝试来进行覆盖更广泛的文法开发。\n",
    "\n",
    "## 树库和文法\n",
    "\n",
    "nltk.corpus.treebank 包含了宾州树库语料的 10% 样本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP-SBJ\n",
      "    (NP (NNP Pierre) (NNP Vinken))\n",
      "    (, ,)\n",
      "    (ADJP (NP (CD 61) (NNS years)) (JJ old))\n",
      "    (, ,))\n",
      "  (VP\n",
      "    (MD will)\n",
      "    (VP\n",
      "      (VB join)\n",
      "      (NP (DT the) (NN board))\n",
      "      (PP-CLR (IN as) (NP (DT a) (JJ nonexecutive) (NN director)))\n",
      "      (NP-TMP (NNP Nov.) (CD 29))))\n",
      "  (. .))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "\n",
    "t = treebank.parsed_sents('wsj_0001.mrg')[0]\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以利用这些数据来帮助开发一个文法。例如在下面的例子中，我们使用一个简单的过滤器找出带句子补语的动词。假设我们已经有一个形如 VP -> V S 的产生式，这个信息使我们能够识别那些包含在 V 的扩张中的特别的动词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(VP\n",
      "  (VBN named)\n",
      "  (S\n",
      "    (NP-SBJ (-NONE- *-1))\n",
      "    (NP-PRD\n",
      "      (NP (DT a) (JJ nonexecutive) (NN director))\n",
      "      (PP\n",
      "        (IN of)\n",
      "        (NP (DT this) (JJ British) (JJ industrial) (NN conglomerate))))))\n"
     ]
    }
   ],
   "source": [
    "def filter(tree):\n",
    "    child_nodes = [child.label() for child in tree\n",
    "                  if isinstance(child, nltk.Tree)]\n",
    "    return (tree.label() == 'VP') and ('S' in child_nodes)\n",
    "\n",
    "print([subtree for tree in treebank.parsed_sents()\n",
    "              for subtree in tree.subtrees(filter)][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk.corpus.ppattach（PP 附着语料库）是另一个有关特别动词配价的信息源。这里我们演示挖掘这个语料库的技术，它找出具有固定的介词和名词的介词短语对，其中介词短语附着到 VP 还是 NP，由选择的动词决定："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%-below-level N: ['left'] V: ['be']\n",
      "%-from-year N: ['was'] V: ['declined', 'dropped', 'fell', 'grew', 'increased', 'plunged', 'rose', 'was']\n",
      "%-in-August N: ['was'] V: ['climbed', 'fell', 'leaping', 'rising', 'rose']\n",
      "%-in-September N: ['increased'] V: ['climbed', 'declined', 'dropped', 'edged', 'fell', 'grew', 'plunged', 'rose', 'slipped']\n",
      "%-in-week N: ['declined'] V: ['was']\n",
      "%-to-% N: ['add', 'added', 'backed', 'be', 'cut', 'go', 'grow', 'increased', 'increasing', 'is', 'offer', 'plummet', 'reduce', 'rejected', 'rise', 'risen', 'shaved', 'wants', 'yield', 'zapping'] V: ['fell', 'rise', 'slipped']\n",
      "%-to-million N: ['declining'] V: ['advanced', 'climbed', 'cutting', 'declined', 'declining', 'dived', 'dropped', 'edged', 'fell', 'gained', 'grew', 'increased', 'jump', 'jumped', 'plunged', 'rising', 'rose', 'slid', 'slipped', 'soared', 'tumbled']\n",
      "1-to-21 N: ['dropped'] V: ['dropped']\n",
      "1-to-33 N: ['gained'] V: ['dropped', 'fell', 'jumped']\n",
      "1-to-4 N: ['added'] V: ['gained']\n",
      "1-to-47 N: ['jumped'] V: ['added', 'rose']\n",
      "1-to-point N: ['ended'] V: ['fell', 'rose']\n",
      "3-to-17 N: ['lost'] V: ['lost']\n",
      "500,000-in-fines N: ['paid'] V: ['paid']\n",
      "6.9-on-scale N: ['registered'] V: ['registered']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "entries = nltk.corpus.ppattach.attachments('training')\n",
    "table = defaultdict(lambda: defaultdict(set))\n",
    "for entry in entries:\n",
    "    key = entry.noun1 + '-' + entry.prep + '-' + entry.noun2\n",
    "    table[key][entry.attachment].add(entry.verb)\n",
    "\n",
    "for key in sorted(table)[:1000]:\n",
    "    if len(table[key]) > 1:\n",
    "        print(key, 'N:', sorted(table[key]['N']), 'V:', sorted(table[key]['V']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLKT 语料库也手机了 10000 句已分析的中文句子，来自现代汉语中央研究院平衡语料库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.corpus.sinica_treebank.parsed_sents()[3450].draw()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sinica-tree.png](resources/sinica-tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 有害的歧义\n",
    "\n",
    "不幸的是，随着文法覆盖范围的增加和输入句子长度的增长，分析树的数量也迅速增加。例如，我们可以造这样的句子：fish fish fish，意思是 fish like to fish for other fish。我们构造一个关于 fish 的玩具文法，并使用前面提到的图表分析器 [nltk.ChartParser](https://www.nltk.org/_modules/nltk/parse/chart.html#ChartParser) 解析："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP fish) (V fish) (NP (NP fish) (Sbar (NP fish) (V fish))))\n",
      "(S (NP (NP fish) (Sbar (NP fish) (V fish))) (V fish) (NP fish))\n"
     ]
    }
   ],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP V NP\n",
    "    NP -> NP Sbar\n",
    "    Sbar -> NP V\n",
    "    NP -> 'fish'\n",
    "    V -> 'fish'\n",
    "\"\"\")\n",
    "\n",
    "tokens = ['fish'] * 5\n",
    "cp = nltk.ChartParser(grammar)\n",
    "for tree in cp.parse(tokens):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随着句子的长度增加到（3，5，7，……），我们得到的分析树的数量是（1，2，5，14，132，429，1430，4862，16796，58786，208012，……）。对于一个长度为 50 的句子有超过 10 的 12 次方种解析方式，没有实际的自然语言处理系统可以为一个句子构建如此多的树，并根据上下文选择一个合适的，但是人类却可以毫不费力地处理这些句子。\n",
    "\n",
    "前面说到的是**结构歧义**，另一种歧义是**词汇歧义**。只要我们试图建立一个广泛覆盖的文法，我们就被迫使词汇条目对它们的词性高度含糊，例如：dog 既可以是名词，也可以是动词；runs 既可以是动词，也可以是名词；所有的词都可以作为名字被引用；大多数的名词也都可以动词化。因此，一个覆盖广泛的文法分析器将对歧义不堪重负。\n",
    "\n",
    "歧义在语言中是不可避免的，导致我们的文法在分析看似平淡无奇的句子时低效得可怕。**概率分析**提供了解决这些问题的方法，它使我们能够以来自语料库的证据为基础对歧义句的解析进行可靠性的排序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加权文法\n",
    "\n",
    "正如我们刚看到的，处理歧义是开发广泛覆盖的分析器的主要挑战。图标分析器提高了计算一个句子的多个分析的效率，但仍然因可能的分析数量过多而不堪重负。**加权文法**和**概率分析算法**为这些问题提供了一个有效的解决方案。\n",
    "\n",
    "首先，我们需要理解符合语法的概念可能是有倾向性的，可以通过概率分析来处理的。思考动词 give，它既需要一个直接宾语（被给予的东西），也需要一个间接宾语（收件人）。这些补语可以按任何顺序出现:\n",
    "\n",
    "    a. Kim gave a bone to the dog.\n",
    "\n",
    "    b. Kim gave the dog a bone.\n",
    "\n",
    "在“介词格”的形式（a）中，直接宾语先出现，然后是包含间接宾语的介词短语；在“双宾语”的形式（b）中，间接宾语先出现，然后是直接宾语。在这种情况下，两种顺序都是可以接受的。然而，如果简介宾语是代词，人们强烈偏好双宾语结构：\n",
    "\n",
    "    a. Kim gives the heebie-jeebies to me (介词格).\n",
    "\n",
    "    b. Kim gives me the heebie-jeebies (双宾语).\n",
    "\n",
    "使用宾州树库样本，我们可以检查包含 give 的所有介词格和双宾语实例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gave NP: the chefs / NP: a standing ovation\n",
      "give NP: advertisers / NP: discounts for maintaining or increasing ad sp...\n",
      "give NP: it / PP-DTV: to the politicians\n",
      "gave NP: them / NP: similar help\n",
      "give NP: them / NP: \n",
      "give NP: only French history questions / PP-DTV: to students in a Europe...\n",
      "give NP: federal judges / NP: a raise\n",
      "give NP: consumers / NP: the straight scoop on the U.S. waste crisis\n",
      "gave NP: Mitsui / NP: access to a high-tech medical product\n",
      "give NP: Mitsubishi / NP: a window on the U.S. glass industry\n",
      "give NP: much thought / PP-DTV: to the rates she was receiving , nor to ...\n",
      "give NP: your Foster Savings Institution / NP: the gift of hope and free...\n",
      "give NP: market operators / NP: the authority to suspend trading in futu...\n",
      "gave NP: quick approval / PP-DTV: to $ 3.18 billion in supplemental appr...\n",
      "give NP: the Transportation Department / NP: up to 50 days to review any...\n",
      "give NP: the president / NP: such power\n",
      "give NP: me / NP: the heebie-jeebies\n",
      "give NP: holders / NP: the right , but not the obligation , to buy a cal...\n",
      "gave NP: Mr. Thomas / NP: only a `` qualified '' rating , rather than ``...\n",
      "give NP: the president / NP: line-item veto power\n"
     ]
    }
   ],
   "source": [
    "def give(t):\n",
    "    return t.label() == 'VP' and len(t) > 2 and t[1].label() == 'NP'\\\n",
    "            and (t[2].label() == 'PP-DTV' or t[2].label() == 'NP')\\\n",
    "            and ('give' in t[0].leaves() or 'gave' in t[0].leaves())\n",
    "        \n",
    "def sent(t):\n",
    "    return ' '.join(token for token in t.leaves() if token[0] not in '*-0')\n",
    "\n",
    "def print_node(t, width):\n",
    "    output = \"%s %s: %s / %s: %s\" % (sent(t[0]), t[1].label(), sent(t[1]), t[2].label(), sent(t[2]))\n",
    "    if len(output) > width:\n",
    "        output = output[:width] + '...'\n",
    "    print(output)\n",
    "    \n",
    "for tree in nltk.corpus.treebank.parsed_sents():\n",
    "    for t in tree.subtrees(give):\n",
    "        print_node(t, 72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以观察到一种强烈的倾向就是最短的补语最先出现，这些偏好可以用加权文法来表示。\n",
    "\n",
    "**概率上下文无关文法**（probabilistic context free grammar，PCFG）是一种上下文无关文法，它的每一个产生式关联一个概率。它会产生与相应的上下文无关文法相同的文本解析，并给每个解析分配一个概率，概率仅仅是它用到的产生式概率的乘积。\n",
    "\n",
    "可以使用 [nltk.PCFG](https://www.nltk.org/_modules/nltk/grammar.html#PCFG) 定义加权文法，每个产生式的权值出现在方括号中，**给定左侧的产生式概率之和必须为 1**，多个产生式既可以分开写也可以组合成一行。[nltk.ViterbiParser](https://www.nltk.org/_modules/nltk/parse/viterbi.html#ViterbiParser) 则是用动态规划实现的一个 PCFG 解析器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Jack) (VP (TV saw) (NP telescopes))) (p=0.064)\n"
     ]
    }
   ],
   "source": [
    "grammar = nltk.PCFG.fromstring(\"\"\"\n",
    "    S -> NP VP [1.0]\n",
    "    VP -> TV NP [0.4] | IV [0.3] | DatV NP NP [0.3]\n",
    "    TV -> 'saw' [1.0]\n",
    "    IV -> 'ate' [1.0]\n",
    "    DatV -> 'gave' [1.0]\n",
    "    NP -> 'telescopes' [0.8]\n",
    "    NP -> 'Jack' [0.2]\n",
    "\"\"\")\n",
    "\n",
    "viterbi_parser = nltk.ViterbiParser(grammar)\n",
    "for tree in viterbi_parser.parse(['Jack', 'saw', 'telescopes']):\n",
    "    print(tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
